# -*- coding: utf-8 -*-
"""Playground.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IFc2zgGKuGP21Gbps1mL6WjO5I1NYeKc
"""

# from google.colab import drive
# drive.mount('/content/drive')

!unzip -uq "/content/drive/My Drive/cell_images.zip" -d "/content/"

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Activation, GlobalAveragePooling2D,Dropout,Dense
from keras.layers.core import Dense, Flatten
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from keras.preprocessing.image import ImageDataGenerator
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
# %matplotlib inline

train_path = '/content/cell_images/Train'
valid_path = '/content/cell_images/Validation'
test_path = '/content/cell_images/Test'

datagen = ImageDataGenerator(rescale=1.0/255)

train_batches = datagen.flow_from_directory(directory=train_path, target_size=(224,224), batch_size=50)
valid_batches = datagen.flow_from_directory(directory=valid_path, target_size=(224,224), batch_size=100)
test_batches = datagen.flow_from_directory(directory=test_path, target_size=(224,224), batch_size=200)

base_model = keras.applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (224,224,3))

# for layer in base_model.layers:
#   layer.trainable=True

# for layer in base_model.layers[:-4]:
#   layer.trainable=False  

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.7)(x)
predictions = Dense(2, activation= 'softmax')(x)

from keras.models import Model
model = Model(inputs = base_model.input, outputs = predictions)
model.summary()

model.compile(optimizer=Adam(lr=0.001),loss="categorical_crossentropy",metrics=["accuracy"])

import matplotlib.pyplot as plt
history=model.fit_generator(generator=train_batches,steps_per_epoch=472,epochs=50,validation_data=valid_batches,validation_steps=10,verbose=2)

# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

